{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          5.1         3.5          1.4         0.2\n",
      "1          4.9         3.0          1.4         0.2\n",
      "2          4.7         3.2          1.3         0.2\n",
      "3          4.6         3.1          1.5         0.2\n",
      "4          5.0         3.6          1.4         0.2\n",
      "       SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "count   150.000000  150.000000   150.000000  150.000000\n",
      "mean      5.843333    3.057333     3.758000    1.199333\n",
      "std       0.828066    0.435866     1.765298    0.762238\n",
      "min       4.300000    2.000000     1.000000    0.100000\n",
      "25%       5.100000    2.800000     1.600000    0.300000\n",
      "50%       5.800000    3.000000     4.350000    1.300000\n",
      "75%       6.400000    3.300000     5.100000    1.800000\n",
      "max       7.900000    4.400000     6.900000    2.500000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Teacher Notes Reasons for Data Transformation.\n",
    "#Variables like Age 18-80 and mileage 0-100,000 have different orders of magnitude\n",
    "#decision trees and regression models can handle that but clustering analysis and neural networks need the variables to\n",
    "#be in a certain scale. Cluster Analysis needs to be in the same order of magnitude.\n",
    "#Traditionally for Neural networks typical its hard to train a model when its not in the same order of magnitude \n",
    "# between 0 and 1, need to scale to that level.\n",
    "\n",
    "#Two traditional ways to scale the data, \n",
    "#First one is the MinMaxScale, where we take the min and max and scale \n",
    "#everything between 0-1. \n",
    "\n",
    "#Second way is to standardized the data, subtract by the mean and divide by the standard divation\n",
    "#everything will be between +- 3 usually.\n",
    "\n",
    "#Both methods MinMaxScaler and StandardScaler require the data to be numeric, need to take out the categorical variables.\n",
    "# Make sure you handle the outliers prior to normalizing the variables, wasn't needed in this dataset so it wasn't performed\n",
    "# But in the realworld there will be outliers and they will scale it near 0 so make sure you deal with the outliers.\n",
    "\n",
    "# Usually for Neural Nets ppl will use MinMaxScale, for Clustering they usually use StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "FILE   = \"IRIS.csv\"\n",
    "\n",
    "df = pd.read_csv( FILE, encoding=\"ISO-8859-1\" )\n",
    "TARGET = \"Species\"\n",
    "\n",
    "X = df.copy()\n",
    "X = X.drop( [TARGET], axis=1 )\n",
    "varNames = X.columns\n",
    "\n",
    "print( X.head() )\n",
    "print( X.describe() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NORMALIZING THE DATA \n",
      "\n",
      "\n",
      "\n",
      "          0         1         2         3\n",
      "0  0.222222  0.625000  0.067797  0.041667\n",
      "1  0.166667  0.416667  0.067797  0.041667\n",
      "2  0.111111  0.500000  0.050847  0.041667\n",
      "3  0.083333  0.458333  0.084746  0.041667\n",
      "4  0.194444  0.666667  0.067797  0.041667\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### MIN MAX SCALER\n",
    "print(\" NORMALIZING THE DATA \\n\\n\\n\")\n",
    "theScaler = MinMaxScaler()\n",
    "theScaler.fit( X )\n",
    "\n",
    "X_MINMAX = theScaler.transform( X )\n",
    "X_MINMAX = pd.DataFrame( X_MINMAX )\n",
    "print( X_MINMAX.head() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nor_SepalLength', 'nor_SepalWidth', 'nor_PetalLength', 'nor_PetalWidth']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "varNames_minmax = []\n",
    "for i in varNames :\n",
    "    newName = \"nor_\" + i\n",
    "    varNames_minmax.append( newName )\n",
    "print( varNames_minmax )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nor_SepalLength  nor_SepalWidth  nor_PetalLength  nor_PetalWidth\n",
      "0         0.222222        0.625000         0.067797        0.041667\n",
      "1         0.166667        0.416667         0.067797        0.041667\n",
      "2         0.111111        0.500000         0.050847        0.041667\n",
      "3         0.083333        0.458333         0.084746        0.041667\n",
      "4         0.194444        0.666667         0.067797        0.041667\n",
      "\n",
      "\n",
      "\n",
      "       nor_SepalLength  nor_SepalWidth  nor_PetalLength  nor_PetalWidth\n",
      "count       150.000000      150.000000       150.000000      150.000000\n",
      "mean          0.428704        0.440556         0.467458        0.458056\n",
      "std           0.230018        0.181611         0.299203        0.317599\n",
      "min           0.000000        0.000000         0.000000        0.000000\n",
      "25%           0.222222        0.333333         0.101695        0.083333\n",
      "50%           0.416667        0.416667         0.567797        0.500000\n",
      "75%           0.583333        0.541667         0.694915        0.708333\n",
      "max           1.000000        1.000000         1.000000        1.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_MINMAX.columns = varNames_minmax\n",
    "print( X_MINMAX.head() )\n",
    "print( \"\\n\\n\")\n",
    "\n",
    "print( X_MINMAX.describe() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nor_SepalLength  nor_SepalWidth  nor_PetalLength  nor_PetalWidth  TARGET\n",
      "0         0.222222        0.625000         0.067797        0.041667  setosa\n",
      "1         0.166667        0.416667         0.067797        0.041667  setosa\n",
      "2         0.111111        0.500000         0.050847        0.041667  setosa\n",
      "3         0.083333        0.458333         0.084746        0.041667  setosa\n",
      "4         0.194444        0.666667         0.067797        0.041667  setosa\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is where the dataset is good to use, variables have been scaled and you bring back in the categorical variables\n",
    "X_MINMAX[ \"TARGET\" ] = df.Species\n",
    "print( X_MINMAX.head() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth  nor_SepalLength  \\\n",
      "0          5.1         3.5          1.4         0.2         0.222222   \n",
      "1          4.9         3.0          1.4         0.2         0.166667   \n",
      "2          4.7         3.2          1.3         0.2         0.111111   \n",
      "3          4.6         3.1          1.5         0.2         0.083333   \n",
      "4          5.0         3.6          1.4         0.2         0.194444   \n",
      "\n",
      "   nor_SepalWidth  nor_PetalLength  nor_PetalWidth  TARGET  \n",
      "0        0.625000         0.067797        0.041667  setosa  \n",
      "1        0.416667         0.067797        0.041667  setosa  \n",
      "2        0.500000         0.050847        0.041667  setosa  \n",
      "3        0.458333         0.084746        0.041667  setosa  \n",
      "4        0.666667         0.067797        0.041667  setosa  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This combines the original data minus the target variable with the normalized variables plus the target variable.\n",
    "X_NEW = pd.concat([ X , X_MINMAX ], axis=1 )\n",
    "print( X_NEW.head() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0          5.1         3.5          1.4         0.2\n",
      "1          4.9         3.0          1.4         0.2\n",
      "2          4.7         3.2          1.3         0.2\n",
      "   nor_SepalLength  nor_SepalWidth  nor_PetalLength  nor_PetalWidth\n",
      "0         0.222222        0.625000         0.067797        0.041667\n",
      "1         0.166667        0.416667         0.067797        0.041667\n",
      "2         0.111111        0.500000         0.050847        0.041667\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#If you get 4 new records to the dataset you can normalize those easily as well example below..\n",
    "\n",
    "X_SMALL = X.iloc[ 0:3, ]\n",
    "print( X_SMALL ) \n",
    "X_SMALL_MINMAX = theScaler.transform( X_SMALL )\n",
    "X_SMALL_MINMAX = pd.DataFrame( X_SMALL_MINMAX )\n",
    "X_SMALL_MINMAX.columns = varNames_minmax\n",
    "print( X_SMALL_MINMAX.head() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  nor_SepalLength\n",
      "0          5.1         0.222222\n",
      "1          4.9         0.166667\n",
      "2          4.7         0.111111\n",
      "3          4.6         0.083333\n",
      "4          5.0         0.194444\n",
      "\n",
      "\n",
      "\n",
      "count    150.000000\n",
      "mean       5.843333\n",
      "std        0.828066\n",
      "min        4.300000\n",
      "25%        5.100000\n",
      "50%        5.800000\n",
      "75%        6.400000\n",
      "max        7.900000\n",
      "Name: SepalLength, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "   SepalLength  nor_SepalLength  calc_SepalLength\n",
      "0          5.1         0.222222          0.222222\n",
      "1          4.9         0.166667          0.166667\n",
      "2          4.7         0.111111          0.111111\n",
      "3          4.6         0.083333          0.083333\n",
      "4          5.0         0.194444          0.194444\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shows the manually calculated scaled values equals the MinMaxScaler values..\n",
    "# Also shows if you have a max value of 10000 (outlier) that it will scale it near zero so make sure you handle outliers\n",
    "# prior to scaling\n",
    "X_TEST = X_NEW[ [\"SepalLength\", \"nor_SepalLength\" ] ]\n",
    "print( X_TEST.head() ) \n",
    "print( \"\\n\\n\")\n",
    "print( X_TEST[\"SepalLength\"].describe() )\n",
    "print( \"\\n\\n\")\n",
    "TEMP = ( X_TEST[\"SepalLength\"] - 4.3 ) / ( 7.9 - 4.3 )       # 4.3 is the original min value...7.9 is the original max value\n",
    "#TEMP = ( X_TEST[\"SepalLength\"] - 4.3 ) / ( 10000 - 4.3 )    # this is what happens when you have outliers.\n",
    "X_TEST = X_TEST.assign( calc_SepalLength = TEMP.values )\n",
    "print( X_TEST.head() ) \n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STANDARDIZING THE DATA \n",
      "\n",
      "\n",
      "\n",
      "          0         1         2         3\n",
      "0 -0.900681  1.019004 -1.340227 -1.315444\n",
      "1 -1.143017 -0.131979 -1.340227 -1.315444\n",
      "2 -1.385353  0.328414 -1.397064 -1.315444\n",
      "3 -1.506521  0.098217 -1.283389 -1.315444\n",
      "4 -1.021849  1.249201 -1.340227 -1.315444\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STANDARD SCALER\n",
    "\n",
    "print(\" STANDARDIZING THE DATA \\n\\n\\n\")\n",
    "\n",
    "theScaler = StandardScaler()\n",
    "theScaler.fit( X )\n",
    "\n",
    "Y_STD = theScaler.transform( X )\n",
    "Y_STD = pd.DataFrame( Y_STD )\n",
    "print( Y_STD.head() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   std_SepalLength  std_SepalWidth  std_PetalLength  std_PetalWidth\n",
      "0        -0.900681        1.019004        -1.340227       -1.315444\n",
      "1        -1.143017       -0.131979        -1.340227       -1.315444\n",
      "2        -1.385353        0.328414        -1.397064       -1.315444\n",
      "3        -1.506521        0.098217        -1.283389       -1.315444\n",
      "4        -1.021849        1.249201        -1.340227       -1.315444\n",
      "\n",
      "\n",
      "\n",
      "       std_SepalLength  std_SepalWidth  std_PetalLength  std_PetalWidth\n",
      "count     1.500000e+02    1.500000e+02     1.500000e+02    1.500000e+02\n",
      "mean     -2.775558e-16   -9.695948e-16    -8.652338e-16   -4.662937e-16\n",
      "std       1.003350e+00    1.003350e+00     1.003350e+00    1.003350e+00\n",
      "min      -1.870024e+00   -2.433947e+00    -1.567576e+00   -1.447076e+00\n",
      "25%      -9.006812e-01   -5.923730e-01    -1.226552e+00   -1.183812e+00\n",
      "50%      -5.250608e-02   -1.319795e-01     3.364776e-01    1.325097e-01\n",
      "75%       6.745011e-01    5.586108e-01     7.627583e-01    7.906707e-01\n",
      "max       2.492019e+00    3.090775e+00     1.785832e+00    1.712096e+00\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "varNames_std = []\n",
    "for i in varNames :\n",
    "    newName = \"std_\" + i\n",
    "    varNames_std.append( newName )\n",
    "\n",
    "Y_STD.columns = varNames_std\n",
    "print( Y_STD.head() )\n",
    "print( \"\\n\\n\")\n",
    "\n",
    "print( Y_STD.describe() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   std_SepalLength  std_SepalWidth  std_PetalLength  std_PetalWidth  TARGET\n",
      "0        -0.900681        1.019004        -1.340227       -1.315444  setosa\n",
      "1        -1.143017       -0.131979        -1.340227       -1.315444  setosa\n",
      "2        -1.385353        0.328414        -1.397064       -1.315444  setosa\n",
      "3        -1.506521        0.098217        -1.283389       -1.315444  setosa\n",
      "4        -1.021849        1.249201        -1.340227       -1.315444  setosa\n",
      "\n",
      "\n",
      "\n",
      "   SepalLength  SepalWidth  PetalLength  PetalWidth  std_SepalLength  \\\n",
      "0          5.1         3.5          1.4         0.2        -0.900681   \n",
      "1          4.9         3.0          1.4         0.2        -1.143017   \n",
      "2          4.7         3.2          1.3         0.2        -1.385353   \n",
      "3          4.6         3.1          1.5         0.2        -1.506521   \n",
      "4          5.0         3.6          1.4         0.2        -1.021849   \n",
      "\n",
      "   std_SepalWidth  std_PetalLength  std_PetalWidth  TARGET  \n",
      "0        1.019004        -1.340227       -1.315444  setosa  \n",
      "1       -0.131979        -1.340227       -1.315444  setosa  \n",
      "2        0.328414        -1.397064       -1.315444  setosa  \n",
      "3        0.098217        -1.283389       -1.315444  setosa  \n",
      "4        1.249201        -1.340227       -1.315444  setosa  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_STD[ \"TARGET\" ] = df.Species\n",
    "print( Y_STD.head() )\n",
    "print( \"\\n\\n\")\n",
    "\n",
    "\n",
    "Y_NEW = pd.concat([ X , Y_STD ], axis=1 )\n",
    "print(Y_NEW.head() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   std_SepalLength  std_SepalWidth  std_PetalLength  std_PetalWidth\n",
      "0        -0.900681        1.019004        -1.340227       -1.315444\n",
      "1        -1.143017       -0.131979        -1.340227       -1.315444\n",
      "2        -1.385353        0.328414        -1.397064       -1.315444\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_SMALL = X.iloc[ 0:3, ]\n",
    "Y_SMALL_STD = theScaler.transform( Y_SMALL )\n",
    "Y_SMALL_STD = pd.DataFrame( Y_SMALL_STD )\n",
    "Y_SMALL_STD.columns = varNames_std\n",
    "print( Y_SMALL_STD.head() )\n",
    "print( \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLength  std_SepalLength\n",
      "0          5.1        -0.900681\n",
      "1          4.9        -1.143017\n",
      "2          4.7        -1.385353\n",
      "3          4.6        -1.506521\n",
      "4          5.0        -1.021849\n",
      "\n",
      "\n",
      "\n",
      "count    150.000000\n",
      "mean       5.843333\n",
      "std        0.828066\n",
      "min        4.300000\n",
      "25%        5.100000\n",
      "50%        5.800000\n",
      "75%        6.400000\n",
      "max        7.900000\n",
      "Name: SepalLength, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "   SepalLength  std_SepalLength  calc_SepalLength\n",
      "0          5.1        -0.900681         -0.897674\n",
      "1          4.9        -1.143017         -1.139200\n",
      "2          4.7        -1.385353         -1.380727\n",
      "3          4.6        -1.506521         -1.501490\n",
      "4          5.0        -1.021849         -1.018437\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_TEST = Y_NEW[ [\"SepalLength\", \"std_SepalLength\" ] ]\n",
    "print( Y_TEST.head() ) \n",
    "print( \"\\n\\n\")\n",
    "print( Y_TEST[\"SepalLength\"].describe() )\n",
    "print( \"\\n\\n\")\n",
    "TEMP = ( Y_TEST[\"SepalLength\"] - 5.843333 ) / 0.828066   # subtract the oiginal mean and divide by the original sd \n",
    "Y_TEST = Y_TEST.assign( calc_SepalLength = TEMP.values )\n",
    "print( Y_TEST.head() ) \n",
    "print( \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
